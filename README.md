# ğŸ“Š DataLakeQ â€” Lightweight Data Quality Gate

**FastAPI + React + Pandas**

DataLakeQ is a plug-and-play **data quality firewall** for Lakehouse pipelines.  
Upload any CSV â†’ get a full trust score, contract validation, PII scan, outlier analysis, and drift detection in one unified dashboard.

**Output:** 0â€“100 Quality Score + **GREEN / YELLOW / RED** Label  
**Engine:** FastAPI + Pandas  
**UI:** React + Vite + TypeScript

---

## ğŸš€ Features

### âœ” Basic Profiling
- Row & column count  
- Missing values (total + per column)  
- Duplicate rows  

### âœ” Contract Validation (YAML)
- Required columns  
- Type mismatches  
- Unique key violations  

### âœ” PII Detection
Detects:
- Emails  
- Phone-like patterns  
- Long numeric ID-like patterns  

### âœ” Outlier Detection
- z-score method  
- Outlier ratio per numeric column  
- Severity classification  

### âœ” Drift Detection
- Baseline auto-created on first run  
- Mean comparison on subsequent runs  
- Flags drift when change > 30%  

### âœ” Scoring Engine
- 0â€“100 score based on all checks  
- Labels:  
  - **GREEN (80â€“100)**  
  - **YELLOW (50â€“79)**  
  - **RED (0â€“49)**  

---

## ğŸ§ª Included Demo Data
Located in `/data`:
- `customers_v1.csv` â†’ baseline dataset  
- `customers_v2.csv` â†’ drift version  

Contract is defined in:  
- `contracts/customers.yaml`

---

## ğŸ›  Setup

### 1. Clone
```bash
git clone https://github.com/<your-username>/DataLakeQuality.git
cd DataLakeQuality
```

### 2. Backend (FastAPI)
```bash
cd backend
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate

pip install -r requirements.txt
uvicorn app.main:app --reload
```

Backend runs at:
- Health: [http://localhost:8000/health](http://localhost:8000/health)  
- Docs: [http://localhost:8000/docs](http://localhost:8000/docs)

### 3. Frontend (React)
```bash
cd ../frontend
npm install
npm run dev
```

Open the dashboard:  
ğŸ‘‰ [http://localhost:5173](http://localhost:5173)

---

## ğŸ§  How to Use (Demo Workflow)
1. Open frontend UI  
2. Dataset name â†’ `customers`  
3. Upload `customers_v1.csv` â†’ baseline created  
4. Upload `customers_v2.csv` â†’ drift detected  
5. View:  
   - Quality score  
   - Contract issues  
   - PII detection  
   - Outliers  
   - Drift analysis  
   - Raw JSON (debug)  

---

## ğŸ“¡ API Endpoint

**POST** `/analyze`

**Form-Data:**
- `dataset_name` (string)  
- `file` (CSV upload)  

**Returns:**
```json
{
  "dataset_name": "customers",
  "quality_score": 75.0,
  "quality_label": "YELLOW",
  "summary": {...},
  "contract": {...},
  "pii": {...},
  "outliers": {...},
  "drift": {...},
  "generated_at": "2025-11-21T15:34:41Z"
}
```

---

## ğŸ“ Project Structure
```
backend/
  app/
    main.py
    core/
      quality_gate.py
      contracts.py
      pii.py
      outliers.py
      drift.py
      scoring.py
    models/
      report.py
    utils/
      io.py
contracts/
  customers.yaml
data/
  customers_v1.csv
  customers_v2.csv
frontend/
  src/App.tsx
```

---

## ğŸ“œ License
MIT License

---

## ğŸ Hackathon Notes
This build is optimized for:
- Fast demo  
- Clear scoring  
- Realistic drift detection  
- Simple, explainable checks  
- Clean React UI  
- Fully reproducible workflow  
```